{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'torch'\n",
    "require 'xlua'\n",
    "require 'optim'\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "-- Model + Loss:\n",
    "local t = require 'model'\n",
    "local model = t.model\n",
    "local fwmodel = t.model\n",
    "local loss = t.loss\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "-- Save light network tools:\n",
    "function nilling(module)\n",
    "   module.gradBias   = nil\n",
    "   if module.finput then module.finput = torch.Tensor() end\n",
    "   module.gradWeight = nil\n",
    "   module.output     = torch.Tensor()\n",
    "   if module.fgradInput then module.fgradInput = torch.Tensor() end\n",
    "   module.gradInput  = nil\n",
    "end\n",
    "\n",
    "function netLighter(network)\n",
    "   nilling(network)\n",
    "   if network.modules then\n",
    "      for _,a in ipairs(network.modules) do\n",
    "         netLighter(a)\n",
    "      end\n",
    "   end\n",
    "end\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "print(sys.COLORS.red .. '==> Defining some tools')\n",
    "\n",
    "-- This matrix records the current confusion across classes\n",
    "local confusion = optim.ConfusionMatrix(classes)\n",
    "\n",
    "-- Log results to files\n",
    "local trainLogger = optim.Logger(paths.concat(opt.save, 'train.log'))\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "print(sys.COLORS.red .. '==> Flattening model parameters')\n",
    "\n",
    "-- Retrieve parameters and gradients:\n",
    "-- this extracts and flattens all the trainable parameters of the mode\n",
    "-- into a 1-dim vector\n",
    "local w,dE_dw = model:getParameters()\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "print(sys.COLORS.red .. '==> Configuring optimizer')\n",
    "\n",
    "local optimState = {\n",
    "   learningRate = opt.learningRate,\n",
    "   momentum = opt.momentum,\n",
    "   weightDecay = opt.weightDecay,\n",
    "   learningRateDecay = opt.learningRateDecay\n",
    "}\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "print(sys.COLORS.red .. '==> Allocating minibatch memory')\n",
    "local x = torch.Tensor(opt.batchSize,trainData.data:size(2), \n",
    "         trainData.data:size(3), trainData.data:size(4)) --faces data\n",
    "local yt = torch.Tensor(opt.batchSize)\n",
    "if opt.type == 'cuda' then \n",
    "   x = x:cuda()\n",
    "   yt = yt:cuda()\n",
    "end\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "print(sys.COLORS.red .. '==> Defining training procedure')\n",
    "\n",
    "local epoch\n",
    "\n",
    "local function train(trainData)\n",
    "\n",
    "   -- epoch tracker\n",
    "   epoch = epoch or 1\n",
    "\n",
    "   -- local vars\n",
    "   local time = sys.clock()\n",
    "\n",
    "   -- shuffle at each epoch\n",
    "   local shuffle = torch.randperm(trainData:size())\n",
    "\n",
    "   -- do one epoch\n",
    "   print(sys.COLORS.green .. '==> Doing epoch on training data:') \n",
    "   print(\"==> Online epoch # \" .. epoch .. ' [batchSize = ' .. opt.batchSize .. ']')\n",
    "   for t = 1,trainData:size(),opt.batchSize do\n",
    "      -- disp progress\n",
    "      xlua.progress(t, trainData:size())\n",
    "      collectgarbage()\n",
    "\n",
    "      -- batch fits?\n",
    "      if (t + opt.batchSize - 1) > trainData:size() then\n",
    "         break\n",
    "      end\n",
    "\n",
    "      -- create mini batch\n",
    "      local idx = 1\n",
    "      for i = t,t+opt.batchSize-1 do\n",
    "         x[idx] = trainData.data[shuffle[i]]\n",
    "         yt[idx] = trainData.labels[shuffle[i]]\n",
    "         idx = idx + 1\n",
    "      end\n",
    "\n",
    "      -- create closure to evaluate f(X) and df/dX\n",
    "      local eval_E = function(w)\n",
    "         -- reset gradients\n",
    "         dE_dw:zero()\n",
    "\n",
    "         -- evaluate function for complete mini batch\n",
    "         local y = model:forward(x)\n",
    "         local E = loss:forward(y,yt)\n",
    "\n",
    "         -- estimate df/dW\n",
    "         local dE_dy = loss:backward(y,yt)   \n",
    "         model:backward(x,dE_dy)\n",
    "\n",
    "         -- update confusion\n",
    "         for i = 1,opt.batchSize do\n",
    "            confusion:add(y[i],yt[i])\n",
    "         end\n",
    "\n",
    "         -- return f and df/dX\n",
    "         return E,dE_dw\n",
    "      end\n",
    "\n",
    "      -- optimize on current mini-batch\n",
    "      optim.sgd(eval_E, w, optimState)\n",
    "   end\n",
    "\n",
    "   -- time taken\n",
    "   time = sys.clock() - time\n",
    "   time = time / trainData:size()\n",
    "   print(\"\\n==> Time to learn 1 sample = \" .. (time*1000) .. 'ms')\n",
    "\n",
    "   -- print confusion matrix\n",
    "   print(confusion)\n",
    "\n",
    "   -- update logger/plot\n",
    "   trainLogger:add{['% mean class accuracy (train set)'] = confusion.totalValid * 100}\n",
    "   if opt.plot then\n",
    "      trainLogger:style{['% mean class accuracy (train set)'] = '-'}\n",
    "      trainLogger:plot()\n",
    "   end\n",
    "\n",
    "   -- save/log current net\n",
    "   local filename = paths.concat(opt.save, 'model.net')\n",
    "   os.execute('mkdir -p ' .. sys.dirname(filename))\n",
    "   print('==> Saving model to '..filename)\n",
    "   model1 = model:clone()\n",
    "   netLighter(model1)\n",
    "   torch.save(filename, model1)\n",
    "\n",
    "   -- next epoch\n",
    "   confusion:zero()\n",
    "   epoch = epoch + 1\n",
    "end\n",
    "\n",
    "-- Export:\n",
    "return train\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
